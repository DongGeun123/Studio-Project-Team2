{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vp5Z7YJRyykz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzXSPHOUyqdU"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import itertools\n",
        "from datasets import load_dataset\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCj0zsrvyqdX"
      },
      "outputs": [],
      "source": [
        "dialog_dataset = load_dataset(\"daily_dialog\")\n",
        "dialog_train = list(itertools.chain(*dialog_dataset[\"train\"][\"dialog\"]))\n",
        "dialog_train_label = list(itertools.chain(*dialog_dataset[\"train\"][\"emotion\"]))\n",
        "dialog_test = list(itertools.chain(*dialog_dataset[\"test\"][\"dialog\"]))\n",
        "dialog_test_label = list(itertools.chain(*dialog_dataset[\"test\"][\"emotion\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rOpHT_uyqdZ"
      },
      "source": [
        "DailyDialog Label\n",
        "\n",
        "no emotion(0), anger(1), disgust(2), fear(3), happiness,(4), sadness(5), surprise(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI0qdwYryqda"
      },
      "outputs": [],
      "source": [
        "print(dialog_test[1])\n",
        "dialog_test_label[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialog_dict = {'anger': 1, 'disgust': 2, 'fear': 3, 'joy': 4, 'neutral': 0, 'sadness': 5, 'surprise': 6}"
      ],
      "metadata": {
        "id": "JGqsoWaiWE6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"anger\" (0), \"disgust\" (1), \"fear\" (2), \"happiness\" (3), \"no emotion\" (4), \"sadness\" (5) or \"surprise\" (6)"
      ],
      "metadata": {
        "id": "BWb9p2S3VvoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sili = load_dataset(\"silicone\", \"dyda_e\")"
      ],
      "metadata": {
        "id": "-Q7a1g6IkN4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silicone_test = dataset_sili[\"test\"][\"Utterance\"]\n",
        "silicone_test_label = dataset_sili[\"test\"][\"Label\"]"
      ],
      "metadata": {
        "id": "03tk_Zd20ptY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silicone_dict = {'anger':0, 'disgust':1, 'fear':2, 'joy':3, 'neutral':4, 'sadness':5, 'surprise':6}"
      ],
      "metadata": {
        "id": "dyJTnAGjVki4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnq6wAl2yqda"
      },
      "source": [
        "j-hartmann/emotion-english-distilroberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzF7ghBCyqdb"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xiquItOyqdc"
      },
      "outputs": [],
      "source": [
        "#Accuracy, Inference time - sort\n",
        "#Dataset: DailyDialog\n",
        "\n",
        "acc_count = 0\n",
        "\n",
        "run_time = []\n",
        "\n",
        "for i in tqdm(range(len(dialog_test))):\n",
        "    start_time = time.time()\n",
        "    sort_list = sorted(classifier(dialog_test[i])[0], key=lambda x:x['score'], reverse=True)\n",
        "    top_label = sort_list[0]['label']\n",
        "    end_time = time.time()\n",
        "    \n",
        "    run_time.append(end_time - start_time)\n",
        "    if dialog_dict[top_label] == dialog_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(dialog_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(run_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY, RUNTIME(SILICONE)\n",
        "\n",
        "acc_count = 0\n",
        "jhartmann_runtime_silicone = []\n",
        "\n",
        "for i in tqdm(range(len(silicone_test))):\n",
        "    start_time = time.time()\n",
        "    sort_list = sorted(classifier(silicone_test[i])[0], key=lambda x:x['score'], reverse=True)\n",
        "    top_label = sort_list[0]['label']\n",
        "    end_time = time.time()\n",
        "\n",
        "    jhartmann_runtime_silicone.append(end_time - start_time)\n",
        "    if  silicone_dict[top_label] ==  silicone_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(silicone_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(jhartmann_runtime_silicone))"
      ],
      "metadata": {
        "id": "19Ao0KDffofs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnr9vLH0yqdd"
      },
      "source": [
        "michellejieli/emotion_text_classifier\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_NcNktxyqde"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"michellejieli/emotion_text_classifier\")\n",
        "classifier(dialog_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_S_e4Jgyqde"
      },
      "outputs": [],
      "source": [
        "classifier(dialog_test[0])[0]['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObfZ5Rbdyqdf"
      },
      "outputs": [],
      "source": [
        "#ACCURACY, RUNTIME(DailyDialog)\n",
        "acc_count = 0\n",
        "michellejieli_runtime = []\n",
        "\n",
        "for i in tqdm(range(len(dialog_test))):\n",
        "    start_time = time.time()\n",
        "    top_label = classifier(dialog_test[i])[0]['label']\n",
        "    end_time = time.time()\n",
        "\n",
        "    michellejieli_runtime.append(end_time - start_time)\n",
        "    if dialog_dict[top_label] == dialog_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(dialog_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(michellejieli_runtime))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY, OUTPUT LABELS(DailyDialog)\n",
        "acc_count = 0\n",
        "output_labels_dd = []\n",
        "\n",
        "for i in tqdm(range(len(dialog_test))):\n",
        "    top_label = classifier(dialog_test[i])[0]['label']\n",
        "    output_labels_dd.append(dialog_dict[top_label])\n",
        "    \n",
        "    if dialog_dict[top_label] == dialog_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(dialog_test))"
      ],
      "metadata": {
        "id": "cM2AkebMxKjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY, RUNTIME(SILICONE)\n",
        "\n",
        "acc_count = 0\n",
        "michellejieli_runtime_silicone = []\n",
        "\n",
        "for i in tqdm(range(len(silicone_test))):\n",
        "    start_time = time.time()\n",
        "    top_label = classifier(silicone_test[i])[0]['label']\n",
        "    end_time = time.time()\n",
        "\n",
        "    michellejieli_runtime_silicone.append(end_time - start_time)\n",
        "    if  silicone_dict[top_label] ==  silicone_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(silicone_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(michellejieli_runtime_silicone))"
      ],
      "metadata": {
        "id": "MXj2N107ko2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY, OUTPUT LABELS(SILICONE)\n",
        "\n",
        "acc_count = 0\n",
        "output_labels_silicone = []\n",
        "\n",
        "for i in tqdm(range(len(silicone_test))):\n",
        "    top_label = classifier(silicone_test[i])[0]['label']\n",
        "    output_labels_silicone.append(silicone_dict[top_label])\n",
        "\n",
        "    if  silicone_dict[top_label] ==  silicone_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(silicone_test))"
      ],
      "metadata": {
        "id": "VX4LlNZzt66G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "arpanghoshal/EkmanClassifier"
      ],
      "metadata": {
        "id": "RiGxHSTdHssL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ekman = pipeline('sentiment-analysis', model='arpanghoshal/EkmanClassifier')"
      ],
      "metadata": {
        "id": "AdFUMeahGdrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY\n",
        "acc_count = 0\n",
        "ekman_runtime = []\n",
        "\n",
        "for i in tqdm(range(len(dialog_test))):\n",
        "    start_time = time.time()\n",
        "    top_label = ekman(dialog_test[i])[0]['label']\n",
        "    end_time = time.time()\n",
        "\n",
        "    ekman_runtime.append(end_time - start_time)\n",
        "    if dialog_dict[top_label] == dialog_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(dialog_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(ekman_runtime))"
      ],
      "metadata": {
        "id": "fZFLwT0yLsdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACCURACY, RUNTIME(SILICONE)\n",
        "\n",
        "acc_count = 0\n",
        "ekman_runtime_silicone = []\n",
        "\n",
        "for i in tqdm(range(len(silicone_test))):\n",
        "    start_time = time.time()\n",
        "    top_label = ekman(silicone_test[i])[0]['label']\n",
        "    end_time = time.time()\n",
        "\n",
        "    ekman_runtime_silicone.append(end_time - start_time)\n",
        "    if  silicone_dict[top_label] ==  silicone_test_label[i]:\n",
        "        acc_count += 1\n",
        "\n",
        "print()\n",
        "print(\"ACCURACY: \", acc_count/len(silicone_test))\n",
        "print(\"AVERAGE RUNTIME: \", np.mean(ekman_runtime_silicone))"
      ],
      "metadata": {
        "id": "CnP44Su-gF0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "neRlj2jDLru6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "studio_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "586458c3b960b500f62250a72c476888b9c37e13ef04baff2222ecedabb40d99"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}